\chapter{Desenvolvimento para Kinect}
\label{cap:DesenvKinect}
Atualmente, os sensores detectores de movimento são utilizados em diversas aplicações, que envolvem desde simples sistemas de alarmes domésticos até radares militares \cite{falahati2013}. O surgimento do Kinect fez com que novas funcionalidades surgissem com relação à utilização desse tipo de sensor, sendo possível a aplicação de \ac{NUI} de uma forma mais eficaz, como, por exemplo, a possibilidade de controlar um computador através de gestos e a criação de aplicações que utilizem o movimento do usuário \cite{catuhe2012}. A utilização de \ac{NUI} implica não somente na ``mímica'' de movimentos do usuário, mas também no controle natural que a pessoa possui sobre uma determinada aplicação \cite{wigdor2011}. Porém, para que fosse possível a utilização de movimentos naturais para controlar aplicações ou realizar tarefas específicas através do uso do Kinect, alguns \acp{SDK} foram desenvolvidos.

\section{OpenNI}
O OpenNI é um \textit{framework} e \ac{SDK} de código aberto utilizado para o desenvolvimento de aplicações e bibliotecas para sensores como o Kinect e similares \cite{openni2013}. Este \textit{framework} é popular entre os desenvolvedores pois apresenta suporte para os sensores que utilizam o \textit{chip} da empresa PrimeSense, sendo assim, é possível desenvolver aplicações que utilizem sensores Kinect,  Asus Xtion e sensores fabricados pela PrimeSense \cite{falahati2013}.

A OpenNI é a organização responsável pelo \textit{framework} de mesmo nome, sendo que o fundador do projeto inicial era a própria PrimeSense \cite{falahati2013}. O projeto foi muito difundido uma vez que esse foi o primeiro \textit{framework} com suporte não-oficial ao Kinect, já que na época não existiam outros \textit{frameworks} para o desenvolvimento de aplicações com este sensor \cite{falahati2013}.

O \ac{SDK} do OpenNI é composto por uma \ac{API} que permite o desenvolvimento de aplicações utilizando sensores 3D \cite{openni2013}, uma camada de abstração de \textit{hardware} que permite que a aplicação seja utilizada em diferentes arquiteturas \cite{hal2009}, e um núcleo que realiza a comunicação com os sensores através do \textit{driver} do dispositivo \cite{openni2013}. Na Figura \ref{fig:openni1} tem-se a arquitetura do OpenNI.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=320px]{imagens/OpenNI1.png}
 \caption{Arquitetura do \ac{SDK} OpenNI}
 \label{fig:openni1}
Fonte: \citet{openni2013}
\end{figure}

A linguagem de programação padrão para o desenvolvimento de aplicações que utilizam o OpenNI é a linguagem C, entretanto é possível utilizar outras linguagens, tais como C++, C\#, Python e Java \cite{openni2013}. Destaca-se que o OpenNI não gera informações sobre detecção de pessoas ou mapeamento de corpo de forma automática, sendo necessário o desenvolvimento de algoritmos para a detecção do esqueleto ou utilizar-se de outras bibliotecas e \textit{middlewares} para a obtenção dessas funcionalidades.

O OpenNI possui algumas adversidades e limitações quando utilizado em conjunto com o sensor Kinect. Uma das limitações que pode-se citar é que o \textit{framework} não possui acesso ao motor de rotação do sensor \cite{openni2013}. O Kinect possui um motor em sua base capaz de inclinar o sensor para cima, para baixo e para os lados \cite{borenstein2012}, sendo assim possível ajustar o melhor ângulo da cena sem a necessidade de mudança de localização do sensor no ambiente. Como o \textit{framework} não provê acesso ao motor, esta funcionalidade não está disponível com o uso do OpenNI. Um outro problema que pode-se citar é com relação à detecção de uma pessoa. A detecção, além de não ocorrer de forma automática, necessita que o usuário fique em uma posição de calibragem conhecida como ``pose Psi'' \cite{borenstein2012}. Esta pose consiste em fazer com que o usuário fique com os braços na altura do ombro e mãos na altura da cabeça, conforme pode-se observar na Figura \ref{fig:psipose1}.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=170px]{imagens/psipose1.png}
 \caption{Pose ``Psi'' para calibragem e detecção do usuário.}
 \label{fig:psipose1}
Fonte: \citet{borenstein2012}
\end{figure}

Algumas vantagens que pode-se citar sobre o uso deste \textit{framework}, é que o mesmo consegue detectar múltiplas pessoas em uma única cena, sendo que cada pessoa deve posicionar-se na pose de calibragem para que seja mapeada corretamente \cite{borenstein2012}. Assim, cada usuário ganha um número identificador único para que haja a distinção dos usuários no ambiente, ou seja, pode-se realizar a manipulação de cada pessoa individualmente \cite{borenstein2012}. Outra vantagem do uso do OpenNI é o fato do \textit{framework} ser multiplataforma, suportando os sistemas operacionais Windows, Linux e OS X \cite{openni2013}. Entretanto, não existem \textit{drivers} oficiais do Kinect para Linux e OS X, sendo necessário o uso de outros \textit{drivers} e aplicações, como, por exemplo, o \textit{libfreenect} \cite{freenect}.

A versão atual do OpenNI provê suporte oficial ao sensor Kinect no sistema operacional Windows, desde que esse seja utilizado juntamente com o \textit{Kinect for Windows SDK} da própria Microsoft \cite{falahati2013}. Isso se dá pelo fato de que durante a instalação do \ac{SDK} da Microsoft, os \textit{drivers} oficiais do Kinect também são instalados, garantindo assim a compatibilidade com o \textit{framework} OpenNI.

\subsection{NiTE}
O \ac{NiTE} é um \textit{middleware} livre (licença Apache 2.0) desenvolvido pela PrimeSense baseado no \textit{framework} OpenNI \cite{falahati2013}. Este \textit{middleware} disponibiliza informações sobre a cena e também possibilita a geração do esqueleto através da detecção do usuário \cite{prime2013}.

O NiTE recebe os dados de profundidade, cor, sinal infravermelho e áudio, fornecidos pelo OpenNI, e através da utilização de algoritmos específicos, efetua o mapeamento da pessoa \cite{prime2013}. Na Figura \ref{fig:nite1} pode-se verificar durante o mapeamento do usuário, a geração de alguns pontos chamados ``juntas'', que estão posicionados em alguns locais específicos do corpo. A união destas juntas gera uma espécie de esqueleto do usuário, sendo que cada junta pode ser acessada de forma individual, e destas, pode-se extrair algumas informações, como, por exemplo, a sua posição na cena \cite{borenstein2012}.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=170px]{imagens/nite1.png}
 \caption{Pontos gerados através da detecção do usuário realizada pelo NiTE.}
 \label{fig:nite1}
Fonte: \citet{falahati2013}
\end{figure}

Um esqueleto gerado pelo NiTE possui 15 juntas que se encontram posicionadas nas mãos, pés, cabeça, pescoço, ombros, tórax, cotovelos, joelhos e quadris \cite{prime2013}. Por padrão, não há juntas nos punhos e nos tornozelos, sendo assim, não é possível detectar a movimentação dos pés e das mãos de forma individual. Além disso, este \textit{middleware} só consegue mapear as pessoas no modo em pé, devido a necessidade de calibragem através da ``pose Psi''. Por fim, o Kinect consegue detectar até 20 pontos em uma pessoa em pé, não sendo possível detectar os pontos restantes com o uso do NiTE \cite{prime2013}.

O uso do NiTE em conjunto com o OpenNI é de extrema importância quando necessita-se do mapeamento do corpo do usuário, já que os algoritmos utilizados para realizar este mapeamento possuem alta complexidade \cite{borenstein2012}. Além disso, este \textit{middleware} é composto por algoritmos que interpretam gestos, movimentos corporais e até mesmo a voz do usuário, fornecendo ao desenvolvedor diversas ferramentas para auxiliar na implementação de uma solução que utilize \ac{NUI} \cite{prime2013}. Além disso, assim como o OpenNI, o NiTE também é multiplataforma e suporta as mesmas linguagens de programação do \ac{SDK} \cite{prime2013}.

\subsection{Python Bindings}
Em Julho de 2013 a PrimeSense disponibilizou um pacote chamado \textit{Python Bindings for OpenNI}. Este pacote torna possível a utilização da linguagem Python para o desenvolvimento de aplicações que utilizam OpenNI e NiTE \cite{prime2013}.

O pacote possui apenas as ligações com a \ac{API} original do OpenNI na linguagem C, não possuindo nenhuma funcionalidade nova ou diferente, preservando inclusive os nomes das chamadas de função originais \cite{prime2013}.

\section{Microsoft Kinect \ac{SDK}}
Logo após o lançamento do Kinect no mercado, o OpenNI era o único \ac{SDK} disponível para o desenvolvimento de aplicações utilizando o sensor. Seis meses após o lançamento do OpenNI, a Microsoft apresentou a primeira versão do Kinect \ac{SDK} beta, composto de diversas bibliotecas e \acp{API} que permitiam o desenvolvimento de aplicações que utilizavam o sensor \textit{Kinect for Xbox 360}  para o sistema operacional Windows \cite{giorioefascinari2013}. Recentemente a Microsoft lançou o sensor \textit{Kinect for Windows}, que é possui apenas uma saída \ac{USB}, ou seja, não é compatível com o \textit{console Xbox 360}, e possui alguns aprimoramentos quando comparado ao Kinect do Xbox, como, por exemplo, uma maior resolução de câmera e uma limitação menor com relação à distância mínima que os objetos devem estar do sensor \cite{kinect4win}.

O \ac{SDK} atual suporta oficialmente as linguagens C++, C\# e Visual Basic para o desenvolvimento das aplicações, entretanto o \ac{SDK} é voltado para o desenvolvimento utilizando-se o \textit{Kinect for Windows} \cite{mssdk}, ou seja, como esse sensor é uma versão aprimorada do \textit{Kinect for Xbox 360}, nem todas as funcionalidades do \ac{SDK} serão compatíveis com o \textit{Kinect for Xbox 360} \cite{catuhe2012}. Além disso, caso um usuário final (que não possua o \ac{SDK} instalado no computador) tente executar a aplicação utilizando o \textit{Kinect for Xbox 360}, um erro irá ocorrer na inicialização do programa, informando ao usuário que o dispositivo não é suportado \cite{catuhe2012}.

O sistema de identificação de usuários funciona de forma similar ao OpenNI, sendo que cada usuário recebe um número identificador para sua distinção na cena. Entretanto, só é possível detectar até seis pessoas na cena e produzir um esqueleto detalhado para apenas duas delas \cite{giorioefascinari2013}.

Ao contrário do OpenNI, o \ac{SDK} da Microsoft não necessita de um \textit{middleware} para geração do esqueleto durante o mapeamento do usuário, ou seja, o próprio \ac{SDK} engloba as funcionalidades do OpenNI e do NiTE \cite{mssdk}. O esqueleto gerado mapeia os todos 20 pontos suportados pelo Kinect no modo em pé (Figura \ref{fig:kinect6}) e 10 pontos no modo sentado. Além disso, o \ac{SDK} não necessita de um pose para a calibragem, detectando o usuário de forma mais rápida, além de prover acesso ao motor de inclinação do sensor \cite{mssdk}.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=170px]{imagens/kinect6.png}
 \caption{Esqueleto gerado através do Microsoft Kinect \ac{SDK} no modo em pé.}
 \label{fig:kinect6}
\end{figure}

O \ac{SDK} não possui código aberto e possui algumas restrições para sua utilização. Uma das restrições que pode-se citar é o uso limitado em conjunto com o sensor \textit{Kinect for Xbox 360}. Após a fase beta, o \ac{SDK} oficial foi lançado juntamente com o sensor \textit{Kinect for Windows}, sendo que o desenvolvimento de aplicações ficou restrito somente à utilização desse mesmo sensor. Dessa forma, só é possível desenvolver aplicações que utilizam o sensor \textit{Kinect for Xbox 360} com o \ac{SDK} beta, ou então, utilizar este sensor somente para o desenvolvimento e para os testes de aplicações para o \textit{Kinect for Windows} \cite{kinect4win}. Conforme os termos de utilização do \ac{SDK}, no caso da utilização do sensor \textit{Kinect for Xbox 360} para o desenvolvimento de aplicações, o desenvolvedor ou distribuidor da aplicação não poderá comercializar ou incentivar o uso da mesma com este sensor \cite{kinect4win}.

\subsection{PyKinect}
O PyKinect é uma ferramenta livre (licença Apache 2.0)  para o \textit{software} Microsoft Visual Studio 2013 que habilita o uso da linguagem Python para o desenvolvimento de aplicações que utilizam o sensor Kinect \cite{pykinect}. A ferramenta funciona de forma similar ao \textit{Python Bindings for OpenNI}, entretanto, o PyKinect utiliza o próprio \ac{SDK} da Microsoft para o processamento das imagens de profundidade e geração do esqueleto durante o mapeamento do usuário. Atualmente, a ferramenta está em uma versão estável, entretanto é compatível somente com a instalação do Python 32-\textit{bits} e necessita que o corpo inteiro esteja visível ao sensor para a geração do esqueleto do usuário \cite{pykinect}.

\section{Testes dos \acp{SDK}}
Os \acp{SDK} citados acima foram testados em conjunto com as aplicações de exemplo, que são disponibilizadas pela OpenNI/PrimeSense e pela Microsoft. Os testes realizados baseiam-se apenas com relação à detecção do usuário e à geração do esqueleto e suas particularidades. O ambiente em que os testes foram realizados foi um ambiente fechado, iluminado por lâmpadas e com influência indireta da luz do sol, conforme pode-se observar na Figura \ref{fig:ambiente1}. A pessoa a ser mapeada estava a uma distância de aproximadamente três metros do sensor e realizou  movimentos com braços, pernas e cabeça neste local. 

\begin{figure}[htbp]
 \centering
 \includegraphics[height=200px]{imagens/ambiente1.png}
 \caption{Ambiente em que os testes dos \acp{SDK} foram feitos.}
 \label{fig:ambiente1}
\end{figure}

Em relação aos testes realizados verificou-se que o esqueleto gerado pelo Microsoft Kinect \ac{SDK} é mais estável do que o gerado pelo NiTE, já que os ruídos da imagem de profundidade fazem com que o esqueleto do NiTE fique mais trêmulo, principalmente quando o usuário está próximo ao sensor. Entretanto, o esqueleto do NiTE aparenta ter movimentação mais natural. Isso deve-se ao fato do Microsoft Kinect \ac{SDK} utilizar um algoritmo de suavização (para evitar que o esqueleto fique trêmulo), deixando o movimento desse com um leve atraso e não acompanhando o usuário de forma tão dinâmica quanto o NiTE. 

Tanto o NiTE quanto o Microsoft Kinect \ac{SDK} apresentaram o mesmo comportamento quando uma área do corpo não pudesse mais ser detectada, como, por exemplo, um braço nas costas. Nesse caso, o esqueleto permaneceu na última posição antes do braço atingir a na área inalcançável, e as juntas perdidas foram destacadas utilizando uma cor diferente. Na Figura \ref{fig:kinect7}a pode-se visualizar na área circulada o tratamento da área inalcançável pelo NiTE, com a geração de ``juntas fantasmas''. Já na na Figura \ref{fig:kinect7}b tem-se o mesmo tratamento feito pelo  Microsoft Kinect \ac{SDK}.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=160px]{imagens/kinect7.png}
 \caption{Tratamento de área inalcançável no NiTE (a) e no Microsoft Kinect \ac{SDK} (b).}
 \label{fig:kinect7}
\end{figure}
\newpage
A utilização de ambos \acp{SDK} apresentou problemas com relação à proximidade do usuário com o sensor. Embora o usuário seja detectado, o esqueleto só é gerado caso a pessoa esteja a uma distância de aproximadamente um metro do sensor. De fato, o Microsoft Kinect \ac{SDK} não gerou o esqueleto a uma distância inferior a esta, mesmo no modo sentado, como pode-se observar na Figura \ref{fig:kinect8}. Já o NiTE gerou o esqueleto, mas com uma quantidade muito grande de ruídos na imagem, deixando o esqueleto muito trêmulo e inviabilizando o uso.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=180px]{imagens/kinect8.png}
 \caption{O Microsoft Kinect \ac{SDK} detecta o usuário mas não consegue gerar o esqueleto à uma curta distância.}
 \label{fig:kinect8}
\end{figure}
%\newpage
O esqueleto do NiTE possui um número menor de juntas no esqueleto, não possuindo as juntas dos tornozelos e dos punhos, incapacitando que o movimento das mão e pés sejam detectados. Entretanto, mesmo com estas opções disponibilizadas pelo Microsoft Kinect \ac{SDK}, o resultado obtido não foi satisfatório, uma vez que o esqueleto não foi capaz de acompanhar as mãos corretamente, como pode-se visualizar nas áreas circuladas da Figura \ref{fig:kinect9}.

\begin{figure}[htbp]
 \centering
 \includegraphics[height=180px]{imagens/kinect9.png}
 \caption{O Microsoft Kinect \ac{SDK} não consegue capturar corretamente a posição das mãos em alguns casos.}
 \label{fig:kinect9}
\end{figure}
\newpage
Portanto, pode-se concluir que ambos os \acp{SDK} possuem limitações com relação ao processamento da imagem de profundidade e da geração do esqueleto do usuário. Isso também deve-se ao fato das limitações de \textit{hardware} do próprio sensor com relação ao ruído na imagem e influência da luz do sol, mesmo que de forma indireta. Todavia, o esqueleto gerado pelo Microsoft Kinect \ac{SDK} possui uma estabilidade maior na cena quando comparado ao esqueleto gerado pelo NiTE. Para os demais casos, o desempenho das ferramentas foi equivalente.

\subsection{Comparativo entre os \acp{SDK}}
Após a análise do funcionamento, restrições e licenciamento dos \acp{SDK} disponíveis para o desenvolvimento de aplicações que utilizam o sensor Kinect, foi realizado um comparativo entre ambos, conforme é exibido na Tabela \ref{tb:comparativo}. A partir dessa análise, optou-se pela utilização do OpenNI e do NiTE para o desenvolvimento da solução. Verificou-se que ambos os \acp{SDK} são equivalentes com relação ao processamento das informações recebidas a partir do Kinect, entretanto, o OpenNI oferece compatibilidade com outros sensores e outros sistemas operacionais. Além disso, as vantagens oferecidas pelo Microsoft Kinect \ac{SDK} não foram satisfatórias, uma vez que os pontos extras detectados pelo esqueleto não foram mapeados de forma correta e a calibragem não é um fator crucial para a aplicação a ser desenvolvida neste trabalho.
\newpage
\begin{table}[ht!]
    \centering
		{\scriptsize
		\caption{Tabela de comparação de recursos dos \acp{SDK}.}
		\label{tb:comparativo}		
		\begin{tabular}{ | l | l | l |}		
		\cline{2-3}
    \multicolumn{1}{l |}{ } & \textbf{OpenNI + NiTE} & \textbf{Microsoft Kinect \ac{SDK}} \\ \hline
    \textbf{Linguagens Suportadas (Padrão)} & C & C++, C\#, VB  \\ \hline
    \textbf{Expansão para Python} & Sim & Sim   \\ \hline
    \textbf{Plataformas} & Windows, Linux, Mac & Windows \\ \hline
		\textbf{Controle do Motor do Sensor} & Não & Sim \\ \hline
		\textbf{Pontos por Esqueleto (Normal)} & 15 & 20 \\ \hline
		\textbf{Pontos por Esqueleto (Sentado)} & Não suporta & 10 \\ \hline
		\textbf{Limite de Pessoas Detectadas} & Não se aplica & 6 \\ \hline
		\textbf{Limite de Esqueletos na Cena} & Não se aplica & 2 \\ \hline
		\textbf{Requer Calibragem} & Sim & Não \\ \hline
		\textbf{Compatível com Outros Sensores} & Sim & Não \\ \hline
		\textbf{Licença} & Livre & Restrita \\ \hline
    \end{tabular}		
		}
\end{table}



